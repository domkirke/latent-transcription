## Cross-modal variational inference for musical transcription and generation

This repository hosts the code for the article "Cross-modal variational inference for musical transcription and generation" submitted at IJCNN 2019. This code allows the training, the analysis, and various generation methods of the models presented in the article. It is divided in four main scripts :  

* `lt_train.py` allows model training
* `lt_analyze.py` performs the evaluation of the selected model 
* `lt_midi.py` performs the model evaluation over the test dataset
* `lt_play.py` allows various methods of generation using the selected model : midi import, audio import, and supervised / free navigation.
